{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result...\n",
      "result...\n",
      "result...\n",
      "result...\n",
      "result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>rel_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Precicion</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F measure</th>\n",
       "      <th colspan=\"2\" halign=\"left\">seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ner_bert-base-uncased_2_2e-5_10_16</td>\n",
       "      <td>relations_more_link_with_so</td>\n",
       "      <td>0.82988</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.83918</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.83452</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               method                     rel_type Precicion  \\\n",
       "                                                                        mean   \n",
       "0  ner_bert-base-uncased_2_2e-5_10_16  relations_more_link_with_so   0.82988   \n",
       "\n",
       "              Recall           F measure           seed            \n",
       "        std     mean       std      mean       std mean       std  \n",
       "0  0.006255  0.83918  0.004427   0.83452  0.005354  3.0  1.581139  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload\n",
    "\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from const import SEEDS, MARKERS_I2B2, MODELS, CONTEXT_WINDOWS, LRS, SEEDS, MARKERS_TBD, TRAIN_BATCH_SIZE\n",
    "\n",
    "task=\"i2b2\"\n",
    "num_train_epochs=10\n",
    "i2b2_dataset=\"i2b2_data/relations\"\n",
    "test_xml_dir = \"preprocess/corpus/i2b2/ground_truth/merged_xml\"\n",
    "train_batch_size = 32\n",
    "\n",
    "BERT_ONLY=False\n",
    "\n",
    "\n",
    "if BERT_ONLY:\n",
    "   relation_type = ['relations_plain_bert']\n",
    "else:\n",
    "    relation_type = ['relations_more_link_with_so'] \n",
    "  \n",
    "MARKERS_I2B2=[\"ner\"]\n",
    "\n",
    "CONTEXT_WINDOWS=[2]\n",
    "\n",
    "SEEDS=[1, 2 ,3 ,4 ,5]\n",
    "\n",
    "res_sub_df_dict = {}\n",
    "\n",
    "res_link_type_df_dict = {}\n",
    "res_doc_dict = {}\n",
    "res_marker_df_dict = {}\n",
    "\n",
    "for marker in MARKERS_I2B2:\n",
    "    for model in MODELS:\n",
    "        for context_window in CONTEXT_WINDOWS:\n",
    "            for lr in LRS:\n",
    "                for train_batch_size in TRAIN_BATCH_SIZE:\n",
    "                    for rel_type in relation_type:\n",
    "                        for seed in SEEDS:\n",
    "                            slurm_out_name = f\"{marker}_{model}_{context_window}_{lr}_{num_train_epochs}_{train_batch_size}_{seed}\"\n",
    "                            dict_out_name = f\"{marker}_{model}_{context_window}_{lr}_{num_train_epochs}_{train_batch_size}\"\n",
    "                            i2b2_rel_model = f\"i2b2_models/{rel_type}/{marker}\"\n",
    "                            output_dir = f\"{i2b2_rel_model}/{slurm_out_name}\"\n",
    "                            \n",
    "                            \n",
    "                            result_file = os.path.join(output_dir, \"result_test.txt\")\n",
    "                            result_file_sub = os.path.join(output_dir, \"result_sub.csv\")\n",
    "                            result_file_link_type = os.path.join(output_dir, \"result_link_type.csv\")\n",
    "                            result_file_marker_type = os.path.join(output_dir, \"result_marker_type.csv\")\n",
    "\n",
    "                            if os.path.exists(result_file):\n",
    "                                print('result...')\n",
    "                                with open(result_file, 'r') as f:\n",
    "                                    lines = f.readlines()\n",
    "                                    res_idx = 6\n",
    "                                    #print(lines[-res_idx:])\n",
    "                                    # res = lines[-res_idx:]\n",
    "                                    res_keys = ['Precicion', 'Recall', 'Average P&R', 'F measure']\n",
    "                                    res_dict = {}\n",
    "                                    \n",
    "                                    for i, (k, line)in enumerate(zip(res_keys, lines[-res_idx:])):\n",
    "                                        if k!='Average P&R':\n",
    "                                            m = re.search(r\".*\\t(.*)\\n.*\", line)\n",
    "                                            val = m.group(1)\n",
    "                                            res_dict[k] = val\n",
    "                                    res_dict['seed'] = seed\n",
    "                                    res_dict['method'] = dict_out_name\n",
    "                                    res_dict['rel_type'] = rel_type\n",
    "                                    res_doc_dict[(slurm_out_name, rel_type)] = res_dict\n",
    "                            else:\n",
    "\n",
    "                                import pdb\n",
    "                                pdb.set_trace()\n",
    "\n",
    "                            if os.path.exists(result_file_sub):\n",
    "                                res_sub_df_dict[(dict_out_name, seed, rel_type)] = pd.read_csv(result_file_sub)\n",
    "                            if os.path.exists(result_file_link_type):    \n",
    "                                res_link_type_df_dict[(dict_out_name, seed, rel_type)] = pd.read_csv(result_file_link_type)\n",
    "                            if os.path.exists(result_file_marker_type):\n",
    "                                res_marker_df_dict[(dict_out_name, seed, rel_type)] = pd.read_csv(result_file_marker_type, index_col=0)\n",
    "                                \n",
    "                                \n",
    "df = pd.DataFrame.from_dict(res_doc_dict, orient=\"index\")       \n",
    "df\n",
    "vals = ['Precicion', 'Recall', 'F measure', 'seed', 'rel_type']                   \n",
    "for v in vals:\n",
    "    if v!= 'rel_type':\n",
    "        \n",
    "        df[v] = pd.to_numeric(df[v])\n",
    "\n",
    "df_grouped = df.groupby(['method', 'rel_type']).agg(['mean', 'std']).sort_values(by=[('F measure', 'mean'), 'method'])\n",
    "\n",
    "\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Precicion</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F measure</th>\n",
       "      <th colspan=\"2\" halign=\"left\">seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel_type</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "      <th>relations_more_link_with_so</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ner_bert-base-uncased_2_2e-5_10_16</th>\n",
       "      <td>0.82988</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.83918</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.83452</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.581139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Precicion  \\\n",
       "                                                          mean   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                     0.82988   \n",
       "\n",
       "                                                                \\\n",
       "                                                           std   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                    0.006255   \n",
       "\n",
       "                                                        Recall  \\\n",
       "                                                          mean   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                     0.83918   \n",
       "\n",
       "                                                                \\\n",
       "                                                           std   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                    0.004427   \n",
       "\n",
       "                                                     F measure  \\\n",
       "                                                          mean   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                     0.83452   \n",
       "\n",
       "                                                                \\\n",
       "                                                           std   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                    0.005354   \n",
       "\n",
       "                                                          seed  \\\n",
       "                                                          mean   \n",
       "rel_type                           relations_more_link_with_so   \n",
       "method                                                           \n",
       "ner_bert-base-uncased_2_2e-5_10_16                         3.0   \n",
       "\n",
       "                                                                \n",
       "                                                           std  \n",
       "rel_type                           relations_more_link_with_so  \n",
       "method                                                          \n",
       "ner_bert-base-uncased_2_2e-5_10_16                    1.581139  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_grouped = df_grouped.pivot(index='method', columns='rel_type')#, values=['rel_type', 'F measure', 'Precision'])#.sort_values(by=[('F measure', 'mean', 'relations_more_link_with_so')])\n",
    "df_grouped\n",
    "#df_grouped[[('Precicion', 'mean', 'relations_plain_bert')]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub group analysis of optimal method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_sub_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} & Count (percentage) &    P &    R &   F1 \\\\\n",
      "\\midrule\n",
      "AFTER   &        2,729 (9.8) & 67.3 & 65.4 & 66.3 \\\\\n",
      "OVERLAP &       9,893 (35.7) & 82.9 & 88.6 & 85.7 \\\\\n",
      "BEFORE  &      15,113 (54.5) & 88.7 & 83.6 & 86.1 \\\\\n",
      "ALL     &     27,735 (100.0) & 83.0 & 83.9 & 83.4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12105/1379149608.py:36: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_final.to_latex(formatters=[f_dis] + [f1 for i in range(1, 4)]))\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "optimal = 'ner_bert-base-uncased_2_2e-5_10_16'\n",
    "\n",
    "vals_rename = {'precision':'P', 'recall':'R', 'f1':'F1'}\n",
    "\n",
    "output_names = vals_rename.values()\n",
    "\n",
    "lst_of_optimal_df = []\n",
    "rel_type='relations_more_link_with_so'\n",
    "\n",
    "for (out_file, seed, relation_type) in res_sub_df_dict.keys():\n",
    "    if out_file==optimal and relation_type==rel_type:\n",
    "        df_format = res_sub_df_dict[(optimal, seed, relation_type)].rename(columns=vals_rename)[output_names].set_axis(['ALL', 'BEFORE', 'AFTER', 'OVERLAP'])#['ner_pos_bert-base-uncased_1_2e-5_10_32']\n",
    "        lst_of_optimal_df.append(df_format)\n",
    "#pd.DataFrame.from_dict(res_sub_df_dict)\n",
    "\n",
    "# 'test': {'BEFORE': 15113, 'AFTER': 2729, 'OVERLAP': 9893}}\n",
    "label_dist = [2729,  9893, 15113]\n",
    "total = sum(label_dist)\n",
    "def f1(x):\n",
    "    return f\"{x*100:.1f}\"\n",
    "def f_dis(x, total=total):\n",
    "    proportion = (x/total)*100\n",
    "    return f\"{x:,} ({proportion:.1f})\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df_final = reduce(lambda x, y: x.add(y, fill_value=0), lst_of_optimal_df) / len(lst_of_optimal_df)\n",
    "df_final = df_final.iloc[[2, 3, 1, 0]]\n",
    "df_final['Count (percentage)'] = label_dist + [total]\n",
    "df_final = df_final[['Count (percentage)', 'P', 'R', 'F1']]\n",
    "\n",
    "print(df_final.to_latex(formatters=[f_dis] + [f1 for i in range(1, 4)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  1,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.819703  0.831770  0.825657  0.825692\n",
       " 1   0.822169  0.872253  0.845821  0.846471\n",
       " 2   0.815570  0.817048  0.816310  0.816308\n",
       " 3   0.819915  0.851971  0.835371  0.835635\n",
       " 4   0.721154  0.719807  0.720482  0.720480\n",
       " 5   0.821360  0.822263  0.821812  0.821811,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  2,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.836731  0.843347  0.840011  0.840026\n",
       " 1   0.860831  0.886018  0.872964  0.873243\n",
       " 2   0.835548  0.838669  0.837108  0.837106\n",
       " 3   0.851960  0.868622  0.860094  0.860210\n",
       " 4   0.711538  0.714976  0.713253  0.713253\n",
       " 5   0.829889  0.831241  0.830565  0.830565,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  3,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.830033  0.841262  0.835600  0.835610\n",
       " 1   0.843400  0.889399  0.865521  0.865789\n",
       " 2   0.826594  0.829106  0.827852  0.827848\n",
       " 3   0.837531  0.867247  0.852031  0.852130\n",
       " 4   0.768116  0.768116  0.768116  0.768116\n",
       " 5   0.826656  0.827755  0.827206  0.827205,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  4,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.830052  0.838793  0.834373  0.834400\n",
       " 1   0.852715  0.889399  0.870196  0.870671\n",
       " 2   0.822795  0.823701  0.823248  0.823248\n",
       " 3   0.842370  0.865261  0.853471  0.853662\n",
       " 4   0.740385  0.748792  0.744578  0.744565\n",
       " 5   0.824216  0.825314  0.824765  0.824765,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  5,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.832351  0.840713  0.836502  0.836511\n",
       " 1   0.853841  0.889399  0.871054  0.871257\n",
       " 2   0.831667  0.830769  0.831217  0.831218\n",
       " 3   0.846030  0.867858  0.856726  0.856805\n",
       " 4   0.722488  0.729469  0.725962  0.725962\n",
       " 5   0.826224  0.827232  0.826728  0.826727}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_link_type_df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  1,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.819703  0.831770  0.825657  0.825692\n",
       " 1   0.822169  0.872253  0.845821  0.846471\n",
       " 2   0.815570  0.817048  0.816310  0.816308\n",
       " 3   0.819915  0.851971  0.835371  0.835635\n",
       " 4   0.721154  0.719807  0.720482  0.720480\n",
       " 5   0.821360  0.822263  0.821812  0.821811,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  2,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.836731  0.843347  0.840011  0.840026\n",
       " 1   0.860831  0.886018  0.872964  0.873243\n",
       " 2   0.835548  0.838669  0.837108  0.837106\n",
       " 3   0.851960  0.868622  0.860094  0.860210\n",
       " 4   0.711538  0.714976  0.713253  0.713253\n",
       " 5   0.829889  0.831241  0.830565  0.830565,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  3,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.830033  0.841262  0.835600  0.835610\n",
       " 1   0.843400  0.889399  0.865521  0.865789\n",
       " 2   0.826594  0.829106  0.827852  0.827848\n",
       " 3   0.837531  0.867247  0.852031  0.852130\n",
       " 4   0.768116  0.768116  0.768116  0.768116\n",
       " 5   0.826656  0.827755  0.827206  0.827205,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  4,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.830052  0.838793  0.834373  0.834400\n",
       " 1   0.852715  0.889399  0.870196  0.870671\n",
       " 2   0.822795  0.823701  0.823248  0.823248\n",
       " 3   0.842370  0.865261  0.853471  0.853662\n",
       " 4   0.740385  0.748792  0.744578  0.744565\n",
       " 5   0.824216  0.825314  0.824765  0.824765,\n",
       " ('ner_bert-base-uncased_2_2e-5_10_16',\n",
       "  5,\n",
       "  'relations_more_link_with_so'):    precision    recall        pr        f1\n",
       " 0   0.832351  0.840713  0.836502  0.836511\n",
       " 1   0.853841  0.889399  0.871054  0.871257\n",
       " 2   0.831667  0.830769  0.831217  0.831218\n",
       " 3   0.846030  0.867858  0.856726  0.856805\n",
       " 4   0.722488  0.729469  0.725962  0.725962\n",
       " 5   0.826224  0.827232  0.826728  0.826727}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_link_type_df_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &         Count &    P &    R &   F1 \\\\\n",
      "\\midrule\n",
      "SEC      & 13,317 (48.0) & 84.7 & 88.5 & 86.5 \\\\\n",
      "ET\\_OTHER &   2,452 (8.8) & 82.6 & 82.8 & 82.7 \\\\\n",
      "TT       &     214 (0.8) & 73.3 & 73.6 & 73.4 \\\\\n",
      "EE       & 11,752 (42.4) & 82.6 & 82.7 & 82.6 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12105/2337884955.py:37: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_final.to_latex(formatters=[f_dis] + [f1 for i in range(1, 4)]))\n"
     ]
    }
   ],
   "source": [
    "res_link_type_df_dict\n",
    "\n",
    "\n",
    "output_names = vals_rename.values()\n",
    "\n",
    "lst_of_optimal_df = []\n",
    "link_types = ['ALL', 'SEC', 'ET_OTHER', 'ET', 'TT', 'EE']\n",
    "for (out_file, seed, rel_trunc_type) in res_link_type_df_dict.keys():\n",
    "    if out_file==optimal: #and rel_trunc_type==\"relations_truncate\":\n",
    "        df_format = res_link_type_df_dict[(optimal, seed, rel_trunc_type)].rename(columns=vals_rename)[output_names].set_axis(link_types)#['ner_pos_bert-base-uncased_1_2e-5_10_32']\n",
    "        lst_of_optimal_df.append(df_format)\n",
    "#pd.DataFrame.from_dict(res_link_type_df_dict)\n",
    "\n",
    "# label_dist = [2725,  9888, 15041]\n",
    "\n",
    "def f1(x):\n",
    "    return f\"{x*100:.1f}\"\n",
    "def f_dis(x, total=total):\n",
    "    proportion = (x/total)*100\n",
    "    return f\"{x:,} ({proportion:.1f})\"\n",
    "    \n",
    "link_type_count = pd.read_csv(os.path.join(f\"/data/chengc7/MarkerTRel/i2b2_data/{relation_type}\", \"test_link_count_by_type.csv\"))\n",
    "df_final = reduce(lambda x, y: x.add(y, fill_value=0), lst_of_optimal_df) / len(lst_of_optimal_df)\n",
    "link_type_count = link_type_count.iloc[[0, 1, 3, 4]]\n",
    "total = link_type_count['0'].values.sum()\n",
    "\n",
    "df_final = df_final[~df_final.index.isin([\"ET\", \"ALL\"])]\n",
    "df_final['Count'] = link_type_count['0'].values\n",
    "df_final = df_final[['Count', 'P', 'R', 'F1']]\n",
    "\n",
    "vals_order = ['']\n",
    "df_final\n",
    "print(df_final.to_latex(formatters=[f_dis] + [f1 for i in range(1, 4)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos_bert-base-uncased_1_2e-5_20_8_1</td>\n",
       "      <td>0.592151</td>\n",
       "      <td>0.592151</td>\n",
       "      <td>0.592151</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_tense_polarity_bert-base-uncased_0_2e-5_20...</td>\n",
       "      <td>0.629292</td>\n",
       "      <td>0.629292</td>\n",
       "      <td>0.629292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              method  precision    recall  \\\n",
       "0                pos_bert-base-uncased_1_2e-5_20_8_1   0.592151  0.592151   \n",
       "1  pos_tense_polarity_bert-base-uncased_0_2e-5_20...   0.629292  0.629292   \n",
       "\n",
       "         f1  seed  \n",
       "0  0.592151   1.0  \n",
       "1  0.629292   1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import sys\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# run python aggregate_tbd.py first \n",
    "df = pd.read_csv(\"agg_tbd.csv\")\n",
    "df.sort_values(by='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
